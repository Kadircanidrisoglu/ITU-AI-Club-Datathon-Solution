{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90279,"databundleVersionId":10477255,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install efficientnet_pytorch\n!pip install torch_optimizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T07:55:05.878241Z","iopub.execute_input":"2024-12-16T07:55:05.879061Z","iopub.status.idle":"2024-12-16T07:55:25.438319Z","shell.execute_reply.started":"2024-12-16T07:55:05.879003Z","shell.execute_reply":"2024-12-16T07:55:25.437190Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import io\nimport random\nimport os\nimport math\nimport timm\nfrom PIL import Image\nfrom tqdm import tqdm\nimport gc\nimport pandas as pd\nimport multiprocessing\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom efficientnet_pytorch import EfficientNet\nfrom torchvision.models import efficientnet_v2_s, efficientnet_v2_m, efficientnet_v2_l\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\n\n\nfrom torch.cuda.amp import GradScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T07:55:25.440038Z","iopub.execute_input":"2024-12-16T07:55:25.440335Z","iopub.status.idle":"2024-12-16T07:55:32.238619Z","shell.execute_reply.started":"2024-12-16T07:55:25.440307Z","shell.execute_reply":"2024-12-16T07:55:32.237755Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Constants\nBATCH_SIZE = 16\nGRADIENT_ACCUMULATION_STEPS = 2\nNUM_WORKERS = 2\nIMAGE_SIZE = 320 \nPIN_MEMORY = True \nPATIENCE = 6\nN_FOLDS = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T07:55:32.239891Z","iopub.execute_input":"2024-12-16T07:55:32.240892Z","iopub.status.idle":"2024-12-16T07:55:32.244789Z","shell.execute_reply.started":"2024-12-16T07:55:32.240850Z","shell.execute_reply":"2024-12-16T07:55:32.243977Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def calculate_dataset_stats(dataframe, image_dir):\n    \"\"\"Calculate mean and std of the dataset\"\"\"\n    print(\"Calculating dataset mean and std...\")\n    \n    # Basic transforms just for stats calculation\n    basic_transforms = transforms.Compose([\n        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n        transforms.ToTensor()\n    ])\n    \n    class StatsDataset(torch.utils.data.Dataset):\n        def __init__(self, df, img_dir, transform):\n            self.df = df\n            self.img_dir = img_dir\n            self.transform = transform\n        \n        def __len__(self):\n            return len(self.df)\n        \n        def __getitem__(self, idx):\n            img_path = os.path.join(self.img_dir, self.df.iloc[idx].filename)\n            image = Image.open(img_path).convert('RGB')\n            return self.transform(image)\n    \n    # Create dataset and loader for stats calculation\n    stats_dataset = StatsDataset(dataframe, image_dir, basic_transforms)\n    stats_loader = DataLoader(\n        stats_dataset,\n        batch_size=32,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY\n    )\n    \n    means = []\n    stds = []\n    \n    # Calculate mean and std\n    for batch in tqdm(stats_loader, desc=\"Calculating dataset statistics\"):\n        means.append(batch.mean((0,2,3)))\n        stds.append(batch.std((0,2,3)))\n    \n    dataset_mean = torch.stack(means).mean(0)\n    dataset_std = torch.stack(stds).mean(0)\n    \n    print(f\"Dataset mean: {dataset_mean}\")\n    print(f\"Dataset std: {dataset_std}\")\n    \n    return dataset_mean, dataset_std\n\nclass ImageDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe: pd.DataFrame, image_dir: str, mode: str, mean=None, std=None):\n        self.df = dataframe\n        self.mode = mode\n        self.image_dir = image_dir\n        \n        # Use calculated stats or ImageNet stats as fallback\n        self.mean = mean if mean is not None else [0.485, 0.456, 0.406]\n        self.std = std if std is not None else [0.229, 0.224, 0.225]\n        \n        if self.mode == 'train':\n            self.transforms = transforms.Compose([\n                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n                transforms.RandomHorizontalFlip(p=0.5),\n                transforms.RandomVerticalFlip(p=0.3),\n                transforms.RandomRotation(15),\n                transforms.ColorJitter(\n                    brightness=0.2, \n                    contrast=0.2, \n                    saturation=0.2, \n                    hue=0.1\n                ),\n                transforms.RandomAffine(\n                    degrees=10, \n                    translate=(0.1, 0.1), \n                    scale=(0.9, 1.1)\n                ),\n                transforms.RandomGrayscale(p=0.1),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=self.mean, std=self.std)\n            ])\n        else:\n            self.transforms = transforms.Compose([\n                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=self.mean, std=self.std)\n            ])\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index: int):\n        try:\n            row = self.df.iloc[index]\n            image_path = os.path.join(self.image_dir, row.filename)\n            \n            try:\n                image = Image.open(image_path).convert('RGB')\n                image = self.transforms(image)\n            except Exception as e:\n                print(f\"Error loading image {image_path}: {str(e)}\")\n                raise e\n\n            if self.mode == 'test':\n                return {\n                    'image': image,\n                    'filename': row.filename\n                }\n            else:\n                return {\n                    'image': image,\n                    'target': row.city_id,\n                    'filename': row.filename\n                }\n        except Exception as e:\n            print(f\"Error in __getitem__ at index {index}: {str(e)}\")\n            raise e\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T07:55:32.246847Z","iopub.execute_input":"2024-12-16T07:55:32.247180Z","iopub.status.idle":"2024-12-16T07:55:32.261191Z","shell.execute_reply.started":"2024-12-16T07:55:32.247156Z","shell.execute_reply":"2024-12-16T07:55:32.260488Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import timm\nfrom timm import create_model\nimport torch.nn as nn\n\nclass EfficientNetV2SmallHead(nn.Module):\n    def __init__(self, num_classes, dropout_rate=0.5):\n        super().__init__()\n        self.encoder = create_model(\n            'tf_efficientnetv2_s',  # Changed to EfficientNetV2 Small\n            pretrained=True,\n            num_classes=0\n        )\n        \n        # Freeze early layers (adjusted for EfficientNetV2 Small)\n        for name, param in list(self.encoder.named_parameters())[:70]:  # Reduced from 100 due to different architecture\n            param.requires_grad = False\n            \n        n_features = self.encoder.num_features  # EfficientNetV2 Small has different feature dimensions\n        \n        # Adjusted head dimensions for EfficientNetV2 Small\n        self.head = nn.Sequential(\n            nn.Linear(n_features, 1024),  # Reduced from 1536 due to smaller backbone\n            nn.LayerNorm(1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(1024, 512),  # Reduced from 768\n            nn.LayerNorm(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(512, 256),  # Reduced from 384\n            nn.LayerNorm(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(256, num_classes)\n        )\n        \n    def forward(self, x):\n        features = self.encoder(x)\n        return self.head(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T07:55:32.262023Z","iopub.execute_input":"2024-12-16T07:55:32.262244Z","iopub.status.idle":"2024-12-16T07:55:32.276222Z","shell.execute_reply.started":"2024-12-16T07:55:32.262222Z","shell.execute_reply":"2024-12-16T07:55:32.275377Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def prepare_data(train_df):\n    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n    train_df['fold'] = -1\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['city'])):\n        train_df.loc[val_idx, 'fold'] = fold\n    \n    return train_df\n\ndef load_data(train_df, test_df, train_dir, test_dir, fold=0, mean=None, std=None):\n    print(\"Preparing data loaders...\")\n    \n    label_encoder = LabelEncoder()\n    train_df['city_id'] = label_encoder.fit_transform(train_df['city'])\n    num_classes = len(label_encoder.classes_)\n    \n    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n    valid_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n    \n    train_dataset = ImageDataset(train_data, train_dir, mode='train', mean=mean, std=std)\n    valid_dataset = ImageDataset(valid_data, train_dir, mode='valid', mean=mean, std=std)\n    test_dataset = ImageDataset(test_df, test_dir, mode='test', mean=mean, std=std)\n\n    print(f\"Train dataset size: {len(train_dataset)}\")\n    print(f\"Validation dataset size: {len(valid_dataset)}\")\n    print(f\"Test dataset size: {len(test_dataset)}\")\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY,\n        drop_last=True\n    )\n    \n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY\n    )\n    \n    return train_loader, valid_loader, test_loader, label_encoder, num_classes\n\ndef calculate_macro_f1(preds, targets, num_classes):\n\n    # Tensor'ları numpy array'e çevir\n    if torch.is_tensor(preds):\n        preds = preds.cpu().numpy()\n    if torch.is_tensor(targets):\n        targets = targets.cpu().numpy()\n    \n    # Her şehir için F1 skorunu hesapla\n    city_f1_scores = []\n    \n    for city_idx in range(num_classes):\n        # True Positives: Doğru tahmin edilen şehir sayısı\n        tp = np.sum((preds == city_idx) & (targets == city_idx))\n        \n        # False Positives: Yanlış şehir olarak tahmin edilenler\n        fp = np.sum((preds == city_idx) & (targets != city_idx))\n        \n        # False Negatives: Kaçırılan şehir tahminleri\n        fn = np.sum((preds != city_idx) & (targets == city_idx))\n        \n        # Precision hesapla\n        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n        \n        # Recall hesapla\n        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n        \n        # F1 skoru hesapla\n        if precision + recall > 0:\n            f1 = 2 * (precision * recall) / (precision + recall)\n        else:\n            f1 = 0.0\n        \n        city_f1_scores.append(f1)\n    \n    # Macro F1: Tüm şehirlerin F1 skorlarının ortalaması\n    macro_f1 = np.mean(city_f1_scores)\n    \n    return float(macro_f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T07:55:32.277275Z","iopub.execute_input":"2024-12-16T07:55:32.277596Z","iopub.status.idle":"2024-12-16T07:55:32.292311Z","shell.execute_reply.started":"2024-12-16T07:55:32.277559Z","shell.execute_reply":"2024-12-16T07:55:32.291506Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def train_step(train_loader, model, criterion, optimizer, epoch, scaler):\n    model.train()\n    running_loss = 0.0\n    running_f1 = 0.0\n    steps = 0\n    \n    optimizer.zero_grad(set_to_none=True)\n    \n    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n    for i, data in pbar:\n        images = data['image'].cuda(non_blocking=True)\n        targets = data['target'].cuda(non_blocking=True)\n        \n        with torch.amp.autocast(device_type='cuda'):\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            loss = loss / GRADIENT_ACCUMULATION_STEPS\n        \n        # Mixed precision backward pass\n        scaler.scale(loss).backward()\n        \n        # Gradient accumulation\n        if (i + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad(set_to_none=True)\n        \n        # Calculate metrics\n        with torch.no_grad():\n            _, preds = torch.max(outputs, 1)\n            f1 = calculate_macro_f1(preds, targets, outputs.size(1))\n        \n        # Update metrics\n        running_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n        running_f1 += f1\n        steps += 1\n        \n        # Update progress bar\n        pbar.set_description(\n            f'Epoch {epoch} - Loss: {running_loss/steps:.4f}, F1: {running_f1/steps:.4f}'\n        )\n        \n        # Clear memory\n        del images, outputs, loss\n        torch.cuda.empty_cache()\n    \n    return running_f1 / steps\n\ndef train_model(train_loader, valid_loader, model, criterion, optimizer, scheduler, scaler):\n    \"\"\"Training loop for fixed number of epochs\"\"\"\n    best_valid_f1 = 0.0\n    num_epochs = 12  # Fixed number of epochs\n    \n    for epoch in range(1, num_epochs + 1):\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n        # Train\n        train_f1 = train_step(train_loader, model, criterion, optimizer, epoch, scaler)\n        \n        # Validate\n        valid_loss, valid_f1 = validate(valid_loader, model, criterion)\n        \n        # Scheduler step\n        scheduler.step()\n        \n        print(f\"Epoch {epoch} - Train F1: {train_f1:.4f}, Valid F1: {valid_f1:.4f}\")\n        \n        # Save best model\n        if valid_f1 > best_valid_f1:\n            best_valid_f1 = valid_f1\n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'epoch': epoch,\n                'best_f1': best_valid_f1,\n            }, 'best_model.pth')\n            print(f\"Saved best model with F1: {best_valid_f1:.4f}\")\n    \n    return best_valid_f1 \n\n@torch.no_grad()\ndef validate(valid_loader, model, criterion):\n    model.eval()\n    running_loss = 0.0\n    running_f1 = 0.0\n    steps = 0\n    \n    for data in tqdm(valid_loader, desc='Validating'):\n        images = data['image'].cuda(non_blocking=True)\n        targets = data['target'].cuda(non_blocking=True)\n        \n        # Updated autocast syntax\n        with torch.amp.autocast(device_type='cuda'):\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n        \n        _, preds = torch.max(outputs, 1)\n        f1 = calculate_macro_f1(preds, targets, outputs.size(1))\n        \n        running_loss += loss.item()\n        running_f1 += f1\n        steps += 1\n        \n        del images, outputs, loss\n        torch.cuda.empty_cache()\n    \n    return running_loss / steps, running_f1 / steps\n\n@torch.no_grad()\ndef predict(test_loader, model, label_encoder):\n    model.eval()\n    predictions = []\n    filenames = []\n    \n    for data in tqdm(test_loader):\n        images = data['image'].cuda(non_blocking=True)\n        \n        with torch.cuda.amp.autocast():\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n        \n        predictions.extend(label_encoder.inverse_transform(preds.cpu().numpy()))\n        filenames.extend(data['filename'])\n        \n        del images, outputs, preds\n        torch.cuda.empty_cache()\n    \n    return filenames, predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T07:55:32.293321Z","iopub.execute_input":"2024-12-16T07:55:32.293654Z","iopub.status.idle":"2024-12-16T07:55:32.311475Z","shell.execute_reply.started":"2024-12-16T07:55:32.293628Z","shell.execute_reply":"2024-12-16T07:55:32.310816Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def generate_submission(test_loader, model, label_encoder):\n    filenames, predictions = predict(test_loader, model, label_encoder)\n    \n    submission = pd.DataFrame({\n        'filename': filenames,\n        'city': predictions\n    })\n    \n    submission.to_csv('submission.csv', index=False)\n    return submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T07:55:32.312388Z","iopub.execute_input":"2024-12-16T07:55:32.312694Z","iopub.status.idle":"2024-12-16T07:55:32.324398Z","shell.execute_reply.started":"2024-12-16T07:55:32.312670Z","shell.execute_reply":"2024-12-16T07:55:32.323492Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"if __name__ == '__main__':\n    # Kaggle paths\n    KAGGLE_INPUT = '/kaggle/input/datathon-ai-qualification-round'\n    \n    # Load data\n    train = pd.read_csv(f'{KAGGLE_INPUT}/train_data.csv')\n    test = pd.read_csv(f'{KAGGLE_INPUT}/test.csv')\n    \n    # Set correct image directories\n    train_dir = f'{KAGGLE_INPUT}/train/train'\n    test_dir = f'{KAGGLE_INPUT}/test/test'\n    \n    # Print dataset info\n    print(\"Dataset Information:\")\n    print(f\"Training samples: {len(train)}\")\n    print(f\"Test samples: {len(test)}\")\n    print(\"\\nSample training data:\")\n    print(train.head())\n    print(\"\\nSample test data:\")\n    print(test.head())\n    \n    # Verify paths exist\n    for path in [train_dir, test_dir]:\n        if not os.path.exists(path):\n            raise ValueError(f\"Path does not exist: {path}\")\n    \n    # First prepare folds - MOVED BEFORE stats calculation\n    train = prepare_data(train)\n    \n    # Calculate dataset statistics ONLY on training fold\n    # Get the data for the training fold (excluding validation data)\n    training_fold = 0  # Assuming we're using fold 0 for validation\n    train_fold_data = train[train['fold'] != training_fold].reset_index(drop=True)\n    \n    print(f\"Calculating statistics using {len(train_fold_data)} training samples...\")\n    train_mean, train_std = calculate_dataset_stats(train_fold_data, train_dir)\n    \n    # Enable memory optimizations\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\n    \n    try:\n        # Set device\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print(f\"Using device: {device}\")\n        \n        # Initialize mixed precision training\n        scaler = torch.amp.GradScaler(device='cuda')\n        \n        # Train on fold 0\n        train_loader, valid_loader, test_loader, label_encoder, num_classes = load_data(\n            train, test, train_dir, test_dir, fold=training_fold,\n            mean=train_mean.tolist(),\n            std=train_std.tolist()\n        )\n        \n        # Initialize model\n        model = EfficientNetV2SmallHead(num_classes=num_classes)\n        model = model.to(device)\n        \n        # Optimizer and criterion\n        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n        optimizer = optim.AdamW(\n        model.parameters(),\n        lr=5e-4,  # Daha düşük learning rate\n        weight_decay=0.05,  # Daha yüksek weight decay\n        betas=(0.9, 0.999)\n    )\n    \n        # Scheduler\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer,\n        T_max=12,  # maximum epoch sayısı\n        eta_min=1e-6  # minimum learning rate\n    )\n        \n        print(\"Starting training...\")\n        # Train model with early stopping\n        best_valid_f1 = train_model(\n            train_loader, valid_loader, model, \n            criterion, optimizer, scheduler, scaler \n        )\n        \n        print(\"Loading best model for submission...\")\n        # Load best model and generate submission\n        checkpoint = torch.load('best_model.pth')\n        model.load_state_dict(checkpoint['model_state_dict'])\n        \n        print(\"Generating submission file...\")\n        submission = generate_submission(test_loader, model, label_encoder)\n        \n        # Save submission\n        submission_path = '/kaggle/working/submission.csv'\n        submission.to_csv(submission_path, index=False)\n        \n        print(f\"Training completed. Best validation F1: {best_valid_f1:.4f}\")\n        print(f\"Submission saved to: {submission_path}\")\n        \n        # Verify submission format\n        print(\"\\nVerifying submission format...\")\n        if set(submission.columns) != {'filename', 'city'}:\n            print(\"Warning: Submission columns do not match required format!\")\n        if not all(submission['city'].isin(['Istanbul', 'Ankara', 'Izmir'])):\n            print(\"Warning: Submission contains invalid city names!\")\n        \n    except Exception as e:\n        print(f\"An error occurred during training: {str(e)}\")\n        raise\n    \n    finally:\n        # Clean up\n        torch.cuda.empty_cache()\n        gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T07:55:32.325735Z","iopub.execute_input":"2024-12-16T07:55:32.326038Z","iopub.status.idle":"2024-12-16T08:14:30.105389Z","shell.execute_reply.started":"2024-12-16T07:55:32.325995Z","shell.execute_reply":"2024-12-16T08:14:30.104491Z"}},"outputs":[{"name":"stdout","text":"Dataset Information:\nTraining samples: 7000\nTest samples: 2000\n\nSample training data:\n          filename      city\n0  image_10000.jpg  Istanbul\n1  image_10001.jpg  Istanbul\n2  image_10002.jpg    Ankara\n3  image_10003.jpg     Izmir\n4  image_10004.jpg    Ankara\n\nSample test data:\n          filename  city\n0  image_17000.jpg   NaN\n1  image_17001.jpg   NaN\n2  image_17002.jpg   NaN\n3  image_17003.jpg   NaN\n4  image_17004.jpg   NaN\nCalculating statistics using 5600 training samples...\nCalculating dataset mean and std...\n","output_type":"stream"},{"name":"stderr","text":"Calculating dataset statistics: 100%|██████████| 175/175 [00:41<00:00,  4.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dataset mean: tensor([0.5070, 0.5327, 0.5378])\nDataset std: tensor([0.2318, 0.2396, 0.2917])\nUsing device: cuda\nPreparing data loaders...\nTrain dataset size: 5600\nValidation dataset size: 1400\nTest dataset size: 2000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/86.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf2e412196494eaf904716d22ca03ac8"}},"metadata":{}},{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 - Loss: 0.8841, F1: 0.6188: 100%|██████████| 350/350 [01:21<00:00,  4.27it/s]\nValidating: 100%|██████████| 88/88 [00:10<00:00,  8.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Train F1: 0.6188, Valid F1: 0.8129\nSaved best model with F1: 0.8129\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 - Loss: 0.6911, F1: 0.7713: 100%|██████████| 350/350 [01:20<00:00,  4.37it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00, 10.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Train F1: 0.7713, Valid F1: 0.8484\nSaved best model with F1: 0.8484\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 - Loss: 0.6319, F1: 0.8000: 100%|██████████| 350/350 [01:20<00:00,  4.36it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00, 10.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Train F1: 0.8000, Valid F1: 0.8318\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 - Loss: 0.5649, F1: 0.8409: 100%|██████████| 350/350 [01:19<00:00,  4.38it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00, 10.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Train F1: 0.8409, Valid F1: 0.8772\nSaved best model with F1: 0.8772\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 - Loss: 0.5119, F1: 0.8759: 100%|██████████| 350/350 [01:19<00:00,  4.38it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00, 10.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 - Train F1: 0.8759, Valid F1: 0.8875\nSaved best model with F1: 0.8875\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 - Loss: 0.4664, F1: 0.9039: 100%|██████████| 350/350 [01:19<00:00,  4.39it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00, 10.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 - Train F1: 0.9039, Valid F1: 0.8835\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 - Loss: 0.4344, F1: 0.9208: 100%|██████████| 350/350 [01:20<00:00,  4.37it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00,  9.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 - Train F1: 0.9208, Valid F1: 0.8984\nSaved best model with F1: 0.8984\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 - Loss: 0.4101, F1: 0.9326: 100%|██████████| 350/350 [01:20<00:00,  4.33it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00,  9.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 - Train F1: 0.9326, Valid F1: 0.9064\nSaved best model with F1: 0.9064\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 - Loss: 0.3814, F1: 0.9517: 100%|██████████| 350/350 [01:19<00:00,  4.38it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00, 10.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 - Train F1: 0.9517, Valid F1: 0.9121\nSaved best model with F1: 0.9121\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 - Loss: 0.3600, F1: 0.9629: 100%|██████████| 350/350 [01:20<00:00,  4.35it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00, 10.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 - Train F1: 0.9629, Valid F1: 0.9157\nSaved best model with F1: 0.9157\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 - Loss: 0.3421, F1: 0.9764: 100%|██████████| 350/350 [01:19<00:00,  4.38it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00, 10.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 - Train F1: 0.9764, Valid F1: 0.9180\nSaved best model with F1: 0.9180\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12 - Loss: 0.3292, F1: 0.9818: 100%|██████████| 350/350 [01:20<00:00,  4.36it/s]\nValidating: 100%|██████████| 88/88 [00:08<00:00, 10.23it/s]\n/tmp/ipykernel_23/4098962473.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load('best_model.pth')\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 - Train F1: 0.9818, Valid F1: 0.9176\nLoading best model for submission...\nGenerating submission file...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/125 [00:00<?, ?it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n  1%|          | 1/125 [00:00<00:51,  2.40it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n  2%|▏         | 3/125 [00:00<00:23,  5.24it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n  4%|▍         | 5/125 [00:00<00:19,  6.12it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n  6%|▌         | 7/125 [00:01<00:17,  6.76it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n  7%|▋         | 9/125 [00:01<00:15,  7.30it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n  9%|▉         | 11/125 [00:01<00:15,  7.47it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 10%|█         | 13/125 [00:01<00:14,  7.76it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 12%|█▏        | 15/125 [00:02<00:14,  7.81it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 14%|█▎        | 17/125 [00:02<00:13,  8.02it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 15%|█▌        | 19/125 [00:02<00:13,  8.09it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 17%|█▋        | 21/125 [00:02<00:13,  7.92it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 18%|█▊        | 23/125 [00:03<00:13,  7.78it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 20%|██        | 25/125 [00:03<00:13,  7.67it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 22%|██▏       | 27/125 [00:03<00:12,  8.07it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 23%|██▎       | 29/125 [00:03<00:11,  8.06it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 25%|██▍       | 31/125 [00:04<00:11,  8.29it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 26%|██▋       | 33/125 [00:04<00:11,  8.36it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 27%|██▋       | 34/125 [00:04<00:10,  8.32it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 28%|██▊       | 35/125 [00:04<00:11,  8.16it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 29%|██▉       | 36/125 [00:04<00:10,  8.37it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 30%|██▉       | 37/125 [00:04<00:10,  8.28it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 30%|███       | 38/125 [00:04<00:10,  8.21it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 31%|███       | 39/125 [00:05<00:10,  8.02it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 32%|███▏      | 40/125 [00:05<00:10,  8.19it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 33%|███▎      | 41/125 [00:05<00:10,  8.17it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 34%|███▎      | 42/125 [00:05<00:10,  7.88it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 34%|███▍      | 43/125 [00:05<00:10,  7.92it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 35%|███▌      | 44/125 [00:05<00:10,  7.82it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 36%|███▌      | 45/125 [00:05<00:09,  8.25it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 37%|███▋      | 46/125 [00:06<00:10,  7.49it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 38%|███▊      | 48/125 [00:06<00:09,  7.74it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 40%|████      | 50/125 [00:06<00:09,  8.04it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 42%|████▏     | 52/125 [00:06<00:08,  8.23it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 42%|████▏     | 53/125 [00:06<00:08,  8.27it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 43%|████▎     | 54/125 [00:06<00:08,  8.12it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 44%|████▍     | 55/125 [00:07<00:08,  8.35it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 45%|████▍     | 56/125 [00:07<00:08,  8.22it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 46%|████▌     | 57/125 [00:07<00:08,  8.33it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 46%|████▋     | 58/125 [00:07<00:08,  8.29it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 47%|████▋     | 59/125 [00:07<00:07,  8.28it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 48%|████▊     | 60/125 [00:07<00:07,  8.13it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 49%|████▉     | 61/125 [00:07<00:07,  8.42it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 50%|████▉     | 62/125 [00:07<00:07,  8.21it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 50%|█████     | 63/125 [00:08<00:07,  8.52it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 51%|█████     | 64/125 [00:08<00:07,  8.17it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 52%|█████▏    | 65/125 [00:08<00:07,  8.37it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 53%|█████▎    | 66/125 [00:08<00:07,  7.91it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 54%|█████▍    | 68/125 [00:08<00:07,  7.80it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 56%|█████▌    | 70/125 [00:08<00:07,  7.77it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 58%|█████▊    | 72/125 [00:09<00:06,  8.08it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 59%|█████▉    | 74/125 [00:09<00:06,  8.09it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 61%|██████    | 76/125 [00:09<00:05,  8.23it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 62%|██████▏   | 78/125 [00:09<00:05,  8.24it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 64%|██████▍   | 80/125 [00:10<00:05,  8.22it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 66%|██████▌   | 82/125 [00:10<00:05,  8.30it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 67%|██████▋   | 84/125 [00:10<00:05,  8.02it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 69%|██████▉   | 86/125 [00:10<00:04,  7.95it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 70%|███████   | 88/125 [00:11<00:04,  8.23it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 72%|███████▏  | 90/125 [00:11<00:04,  7.87it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 74%|███████▎  | 92/125 [00:11<00:04,  8.14it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 75%|███████▌  | 94/125 [00:11<00:04,  7.49it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 77%|███████▋  | 96/125 [00:12<00:03,  7.75it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 78%|███████▊  | 98/125 [00:12<00:03,  7.73it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 80%|████████  | 100/125 [00:12<00:03,  7.83it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 82%|████████▏ | 102/125 [00:12<00:02,  8.01it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 83%|████████▎ | 104/125 [00:13<00:02,  7.85it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 85%|████████▍ | 106/125 [00:13<00:02,  7.95it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 86%|████████▋ | 108/125 [00:13<00:02,  8.02it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 88%|████████▊ | 110/125 [00:13<00:01,  8.17it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 90%|████████▉ | 112/125 [00:14<00:01,  8.22it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 91%|█████████ | 114/125 [00:14<00:01,  8.16it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 93%|█████████▎| 116/125 [00:14<00:01,  8.23it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 94%|█████████▍| 118/125 [00:14<00:00,  8.06it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 96%|█████████▌| 120/125 [00:15<00:00,  8.26it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 98%|█████████▊| 122/125 [00:15<00:00,  8.27it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n 99%|█████████▉| 124/125 [00:15<00:00,  8.49it/s]/tmp/ipykernel_23/3445634582.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n100%|██████████| 125/125 [00:15<00:00,  7.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training completed. Best validation F1: 0.9180\nSubmission saved to: /kaggle/working/submission.csv\n\nVerifying submission format...\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}